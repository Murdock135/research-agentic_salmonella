import os

from config import Config
from langchain_ollama import ChatOllama

if __name__=="__main__":
    # load data
    breakpoint()
    print(0)


# -----------------------------------------------------------------
# discarded code
# -----------------------------------------------------------------
    # llm parameters
#    temperature = 0
#    max_tokens = 200

#    llm=ChatOllama(
#            model="llama3.2:latest"
#            )
#
#    messages = [
#            (
#                "system",
#                "You are a helpful assistant that translates English to Malay. Translate the user's sentence"
#                ),
#            ("human", "I love programming."),
#            ]
#    ai_msg = llm.invoke(messages)
#    print(ai_msg)


